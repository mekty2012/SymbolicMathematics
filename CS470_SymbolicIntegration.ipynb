{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oub16kLOqpRd"
      },
      "source": [
        "## 1. Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcYEOLiPqVgd"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch\n",
        "\n",
        "import sympy as sp\n",
        "import os\n",
        "from argparse import Namespace\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "import time\n",
        "from itertools import product\n",
        "\n",
        "from src.utils import AttrDict\n",
        "from src.envs import build_env\n",
        "from src.envs.sympy_utils import simplify\n",
        "model_path = './fwd_bwd.pth'\n",
        "params = AttrDict({\n",
        "\n",
        "    # environment parameters\n",
        "    'env_name': 'char_sp',\n",
        "    'int_base': 10,\n",
        "    'balanced': False,\n",
        "    'positive': True,\n",
        "    'precision': 10,\n",
        "    'n_variables': 1,\n",
        "    'n_coefficients': 0,\n",
        "    'leaf_probs': '0.75,0,0.25,0',\n",
        "    'max_len': 512,\n",
        "    'max_int': 5,\n",
        "    'max_ops': 15,\n",
        "    'max_ops_G': 15,\n",
        "    'clean_prefix_expr': True,\n",
        "    'rewrite_functions': '',\n",
        "    'tasks': 'prim_fwd',\n",
        "    'operators': 'add:10,sub:3,mul:10,div:5,sqrt:4,pow2:4,pow3:2,pow4:1,pow5:1,ln:4,exp:4,sin:4,cos:4,tan:4,asin:1,acos:1,atan:1,sinh:1,cosh:1,tanh:1,asinh:1,acosh:1,atanh:1',\n",
        "\n",
        "    # model parameters\n",
        "    'cpu': False,\n",
        "    'emb_dim': 1024,\n",
        "    'n_enc_layers': 6,\n",
        "    'n_dec_layers': 6,\n",
        "    'n_heads': 8,\n",
        "    'dropout': 0,\n",
        "    'attention_dropout': 0,\n",
        "    'sinusoidal_embeddings': False,\n",
        "    'share_inout_emb': True,\n",
        "    'reload_model': model_path,\n",
        "\n",
        "})\n",
        "env = build_env(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drz9A5Scqssz"
      },
      "source": [
        "## 2. Seed randoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhlwaA3YqmqX",
        "outputId": "d790aa02-bc32-4e18-f2b6-f8841c35f7a6"
      },
      "outputs": [],
      "source": [
        "manual_seed = \"7777\".__hash__() % (2 ** 32) #random.randint(1, 10000)\n",
        "print(\"Random Seed: \", manual_seed)\n",
        "random.seed(manual_seed)\n",
        "torch.manual_seed(manual_seed)\n",
        "np.random.seed(manual_seed)\n",
        "\n",
        "!mkdir results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0mjin3B19mG"
      },
      "source": [
        "## 3. Implement preprocessing / postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L35Ohs0mqwH0"
      },
      "outputs": [],
      "source": [
        "x = env.local_dict['x']\n",
        "F_infix = 'ln(cos(x + exp(x)) * sin(x**2 + 2) * exp(x) / x)'\n",
        "F = sp.S(F_infix, locals=env.local_dict)\n",
        "F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = F.diff(x)\n",
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "F_postfix = env.sympy_to_postfix(F)\n",
        "f_postfix = env.sympy_to_postfix(f)\n",
        "f_prefix = env.sympy_to_prefix(f)\n",
        "print(f\"F postfix : {len(F_postfix)}\")\n",
        "print(f\"f postfix : {len(f_postfix)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n8_8iQekpoI"
      },
      "source": [
        "## 4. Implement models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4R-DInW2CAM"
      },
      "source": [
        "### 1. ChildSumLSTM\n",
        "\n",
        "Given inp $v$, hiddens $h_i$, cells $c_i$, computes\n",
        "\n",
        "$h = \\sum_{i=1}^C h_i$\n",
        "\n",
        "$v_i = \\sigma(I_i(v) + H_i(h))$\n",
        "\n",
        "$v_o = \\sigma(I_o(v) + H_o(h)$\n",
        "\n",
        "$v_u = \\tanh(I_u(v) + H_u(h)$\n",
        "\n",
        "$v_{f}^i = \\sigma(I_f(v) + h_i)$\n",
        "\n",
        "$v_c = v_i + v_u + \\sum_{i=1}^C v_{f}^i * c_i$\n",
        "\n",
        "$v_h = v_o * \\tanh(v_c)$\n",
        "\n",
        "You can stack ChildSumLSTM by letting parameter `return_sequence = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R53QKKkAxrOO"
      },
      "outputs": [],
      "source": [
        "def postorder_checker(depth):\r\n",
        "    if depth == 1:\r\n",
        "        return [True]\r\n",
        "    else:\r\n",
        "        return postorder_checker(depth - 1) * 2 + [False]\r\n",
        "\r\n",
        "class ChildSumTreeLSTM(nn.Module):\r\n",
        "    def __init__(self, in_dim, cell_dim, return_sequence = False):\r\n",
        "        super(ChildSumTreeLSTM, self).__init__()\r\n",
        "        self.return_sequence = return_sequence\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        self.tanh = nn.Tanh()\r\n",
        "\r\n",
        "        self.in_dim = in_dim\r\n",
        "        self.cell_dim = cell_dim\r\n",
        "        \r\n",
        "        self.input_Wf = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.hidden_Wf = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.input_Wi = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.hidden_Wi = nn.Linear(self.cell_dim, self.cell_dim, bias = False)\r\n",
        "        self.input_Wo = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.hidden_Wo = nn.Linear(self.cell_dim, self.cell_dim, bias = False)\r\n",
        "        self.input_Wu = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.hidden_Wu = nn.Linear(self.cell_dim, self.cell_dim, bias = False)\r\n",
        "        \r\n",
        "        \r\n",
        "    def forward(self, inps):\r\n",
        "        # Assumes that input is given as postorder traversal.\r\n",
        "        # inps : (batch_size, node_num, input_dim)\r\n",
        "        batch_size = inps.shape[0]\r\n",
        "        if self.return_sequence:\r\n",
        "            result_seq = None\r\n",
        "        stack = []\r\n",
        "        size = inps.shape[1] # Get number of nodes\r\n",
        "        depth = size.bit_length()\r\n",
        "        checker = postorder_checker(depth)\r\n",
        "        for i, tf in enumerate(checker):\r\n",
        "            inp = inps[:, i, :]\r\n",
        "            if tf: # external node\r\n",
        "                left_hidden = torch.zeros([batch_size, self.cell_dim])\r\n",
        "                right_hidden = torch.zeros([batch_size, self.cell_dim])\r\n",
        "                left_cell = torch.zeros([batch_size, self.cell_dim])\r\n",
        "                right_cell = torch.zeros([batch_size, self.cell_dim])\r\n",
        "                new_hidden = torch.zeros([batch_size, self.cell_dim])\r\n",
        "            else:\r\n",
        "                assert len(stack) >= 2\r\n",
        "                left_hidden, left_cell = stack.pop()\r\n",
        "                right_hidden, right_cell = stack.pop()\r\n",
        "                new_hidden = left_hidden + right_hidden\r\n",
        "                \r\n",
        "            i_vec = self.sigmoid(self.input_Wi(inp) + self.hidden_Wi(new_hidden)) # (batch_size, cell_dim)\r\n",
        "            o_vec = self.sigmoid(self.input_Wo(inp) + self.hidden_Wo(new_hidden)) # (batch_size, cell_dim)\r\n",
        "            u_vec = self.tanh(self.input_Wu(inp) + self.hidden_Wu(new_hidden)) # (batch_size, cell_dim)\r\n",
        "\r\n",
        "            flat_hidden = torch.cat([torch.unsqueeze(left_hidden, dim=1), torch.unsqueeze(right_hidden, dim=1)], dim=1) # (batch_size, 2, cell_dim)\r\n",
        "            input_f_vec = torch.unsqueeze(self.input_Wf(inp), dim=1).repeat_interleave(2, dim=1)\r\n",
        "            hidden_f_vec = self.hidden_Wf(flat_hidden).view(-1, 2, self.cell_dim)\r\n",
        "            f_vec = self.sigmoid(input_f_vec + hidden_f_vec)\r\n",
        "               \r\n",
        "            c_vec = i_vec * u_vec + torch.sum(torch.cat([torch.unsqueeze(left_cell, dim=1), torch.unsqueeze(right_cell, dim=1)], dim=1) * f_vec, 1)\r\n",
        "            h_vec = o_vec * self.tanh(c_vec)\r\n",
        "            \r\n",
        "            stack.append((h_vec, c_vec))\r\n",
        "            if self.return_sequence:\r\n",
        "                if result_seq is None:\r\n",
        "                    result_seq = torch.unsqueeze(h_vec, dim=1)\r\n",
        "                else:\r\n",
        "                    result_seq = torch.cat([result_seq, torch.unsqueeze(h_vec, dim=1)], dim=1)\r\n",
        "        assert len(stack) == 1\r\n",
        "        if self.return_sequence:\r\n",
        "            return result_seq\r\n",
        "        else:\r\n",
        "            return stack[0]\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVfrmV4m3ie_"
      },
      "source": [
        "### 2. Binary Tree LSTM\n",
        "\n",
        "Given inp $v$, hiddens $h_l, h_r$, cells $c_l, c_r$, computes\n",
        "\n",
        "$v_i = \\sigma(I_i(v) + H_i^l(h_l) + H_i^r(h_r)$\n",
        "\n",
        "$v_u = \\sigma(I_u(v) + H_u^l(h_l) + H_u^r(h_r)$\n",
        "\n",
        "$v_o = \\tanh(I_o(v) + H_o^l(h_l) + H_o^r(h_r)$\n",
        "\n",
        "$v_{f}^l = \\sigma(I_{lf}^l(v) + H_{lf}^l(h_l) + H_{lf}^l(h_r)$\n",
        "\n",
        "$v_{f}^r = \\sigma(I_{rf}^l(v) + H_{rf}^l(h_l) + H_{rf}^l(h_r)$\n",
        "\n",
        "$v_c = v_i + v_u + v_f^l * c_l + v_f^r * c_r$\n",
        "\n",
        "$v_h = v_o * \\tanh(v_c)$\n",
        "\n",
        "You can stack BinaryTreeLSTM by letting parameter `return_sequence = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdxqhmmJBCac"
      },
      "outputs": [],
      "source": [
        "class BinaryTreeLSTM(nn.Module):\r\n",
        "    def __init__(self, in_dim, cell_dim, return_sequence = False):\r\n",
        "        super(BinaryTreeLSTM, self).__init__()\r\n",
        "        self.in_dim = in_dim\r\n",
        "        self.cell_dim = cell_dim\r\n",
        "        self.return_sequence = return_sequence\r\n",
        "\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "        self.tanh = nn.Tanh()\r\n",
        "\r\n",
        "        self.input_Wi = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.input_Wo = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.input_Wu = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.input_Wlf = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "        self.input_Wrf = nn.Linear(self.in_dim, self.cell_dim)\r\n",
        "\r\n",
        "        self.left_Wi = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.left_Wo = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.left_Wu = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.left_Wlf = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.left_Wrf = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        \r\n",
        "        self.right_Wi = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.right_Wo = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.right_Wu = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.right_Wlf = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "        self.right_Wrf = nn.Linear(self.cell_dim, self.cell_dim, bias=False)\r\n",
        "\r\n",
        "    def forward(self, inps):\r\n",
        "        batch_size = inps.shape[0]\r\n",
        "        if self.return_sequence:\r\n",
        "            result_seq = None\r\n",
        "        stack = []\r\n",
        "        size = inps.shape[1] # Get number of nodes\r\n",
        "        depth = size.bit_length()\r\n",
        "        checker = postorder_checker(depth)\r\n",
        "        for i, tf in enumerate(checker):\r\n",
        "            inp = inps[:, i, :]\r\n",
        "            if tf:\r\n",
        "                left_hidden = torch.zeros(batch_size, self.cell_dim)\r\n",
        "                right_hidden = torch.zeros(batch_size, self.cell_dim)\r\n",
        "                left_cell = torch.zeros(batch_size, self.cell_dim)\r\n",
        "                right_cell = torch.zeros(batch_size, self.cell_dim)\r\n",
        "            else:\r\n",
        "                right_hidden, right_cell = stack.pop()\r\n",
        "                left_hidden, left_cell = stack.pop()\r\n",
        "            \r\n",
        "            i_vec = self.sigmoid(self.input_Wi(inp) + self.left_Wi(left_hidden) + self.right_Wi(right_hidden))\r\n",
        "            o_vec = self.sigmoid(self.input_Wo(inp) + self.left_Wo(left_hidden) + self.right_Wo(right_hidden))\r\n",
        "            u_vec = self.tanh(self.input_Wu(inp) + self.left_Wu(left_hidden) + self.right_Wu(right_hidden))\r\n",
        "            left_f_vec = self.sigmoid(self.input_Wlf(inp) + self.left_Wlf(left_hidden) + self.right_Wlf(right_hidden))\r\n",
        "            right_f_vec = self.sigmoid(self.input_Wrf(inp) + self.left_Wrf(left_hidden) + self.right_Wrf(right_hidden))\r\n",
        "\r\n",
        "            c_vec = i_vec * u_vec + left_f_vec * left_cell + right_f_vec * right_cell\r\n",
        "            h_vec = o_vec * self.tanh(c_vec)\r\n",
        "\r\n",
        "            stack.append((h_vec, c_vec))\r\n",
        "            if self.return_sequence:\r\n",
        "                if result_seq is None:\r\n",
        "                    result_seq = torch.unsqueeze(h_vec, dim=1)\r\n",
        "                else:\r\n",
        "                    result_seq = torch.cat([result_seq, torch.unsqueeze(h_vec, dim=1)], dim=1)\r\n",
        "        \r\n",
        "        assert len(stack) == 1\r\n",
        "        if self.return_sequence:\r\n",
        "            return result_seq\r\n",
        "        else:\r\n",
        "            return stack[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAIC14qi3ShB"
      },
      "source": [
        "### 3. Recursive Neural Network\n",
        "\n",
        "Given input $v_i$, left $v_l$, right $v_r$, computes\n",
        "\n",
        "$v = act(L_i(v_i) + L_l(v_l) + L_r(v_r))$\n",
        "\n",
        "You can stack RecursiveNN by letting parameter `return_sequence = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8rsLbaPJjSm"
      },
      "outputs": [],
      "source": [
        "class RecursiveNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, return_sequence = False):\n",
        "        super(RecursiveNN, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.activation = nn.ReLU()\n",
        "        self.return_sequence = return_sequence\n",
        "\n",
        "        self.inp_linear = nn.Linear(self.in_dim, self.hidden_dim)\n",
        "        self.left_linear = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)\n",
        "        self.right_linear = nn.Linear(self.hidden_dim, self.hidden_dim, bias=False)\n",
        "    \n",
        "    def forward(self, inps):\n",
        "        batch_size = inps.shape[0]\n",
        "        if self.return_sequence:\n",
        "            result_seq = None\n",
        "        stack = []\n",
        "        size = inps.shape[1] # Get number of nodes\n",
        "        depth = size.bit_length()\n",
        "        checker = postorder_checker(depth)\n",
        "        for i, tf in enumerate(checker):\n",
        "            inp = inps[:, i, :]\n",
        "            if tf:\n",
        "                res = self.activation(self.inp_linear(inp))\n",
        "                stack.append(res)\n",
        "                if self.return_sequence:\n",
        "                    if result_seq is None:\n",
        "                        result_seq = torch.unsqueeze(res, dim=1)\n",
        "                    else:\n",
        "                        result_seq = torch.cat([result_seq, torch.unsqueeze(res, dim=1)], dim=1)\n",
        "            else:\n",
        "                right = stack.pop()\n",
        "                left = stack.pop()\n",
        "                res = self.activation(self.inp_linear(inp) + self.left_linear(left) + self.right_linear(right))\n",
        "                stack.append(res)\n",
        "                if self.return_sequence:\n",
        "                    if result_seq is None:\n",
        "                        result_seq = torch.unsqueeze(res, dim=1)\n",
        "                    else:\n",
        "                        result_seq = torch.cat([result_seq, torch.unsqueeze(res, dim=1)], dim=1)\n",
        "        assert len(stack) == 1\n",
        "        if self.return_sequence:\n",
        "            return result_seq\n",
        "        else:\n",
        "            return stack[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcD9i8hy4iXv"
      },
      "source": [
        "### 4. Compositional Semantics\n",
        "\n",
        "Compose the opeartors.\n",
        "\n",
        "Each unary ops corresponds to $n \\times n$ matrix, binary ops corresponds to $2n \\times n$ matrix, terminal corresponds to length $n$ vector.\n",
        "\n",
        "You can not stack this module.\n",
        "\n",
        "To stack, try rewriting unary/binary ops to stacked modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlBnKR8mNZUi"
      },
      "outputs": [],
      "source": [
        "class CompositionalSemantics(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(CompositionalSemantics, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.activation = nn.ReLU()\n",
        "        self.unary_ops = nn.ModuleDict({\n",
        "            \"exp\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"log\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"sqrt\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"sin\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"cos\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"tan\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"asin\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"acos\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"atan\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"sinh\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"cosh\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"tanh\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"asinh\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"acosh\" : nn.Linear(self.hidden_dim, self.hidden_dim), \n",
        "            \"atanh\" : nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        })\n",
        "        \n",
        "        self.binary_ops = nn.ModuleDict({\n",
        "            \"+\" : nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            \"-\" : nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            \"*\" : nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            \"/\" : nn.Linear(self.hidden_dim * 2, self.hidden_dim)\n",
        "        })\n",
        "        self.terminals = nn.ParameterDict({\n",
        "            \"x\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"-5\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"-4\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"-3\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"-2\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"-1\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"1\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"2\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"3\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"4\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True),\n",
        "            \"5\" : nn.Parameter(torch.rand(self.hidden_dim), requires_grad = True)\n",
        "        })\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"Assumes inputs are given as postorder traversal\"\"\"\n",
        "        res = []\n",
        "        for i in range(len(inp)):\n",
        "            stack = []\n",
        "            for i, curr in enumerate(inp):\n",
        "                if curr in self.unary_ops:\n",
        "                    param = stack.pop()\n",
        "                    func = self.unary_ops[curr]\n",
        "                    stack.append(self.activation(func(param)))\n",
        "                elif curr in self.binary_ops:\n",
        "                    right_param = stack.pop()\n",
        "                    left_param = stack.pop()\n",
        "                    func = self.binary_ops[curr]\n",
        "                    stack.append(self.activation(func(torch.cat([left_param, right_param], dim=1))))\n",
        "                elif curr in self.terminals:\n",
        "                    stack.append(self.terminals[curr])\n",
        "            assert len(stack) == 1\n",
        "            res.append(torch.unsqueeze(stack.pop(), 0))\n",
        "        return torch.cat(res, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMeEf8_445kG"
      },
      "source": [
        "### 5. Code2Seq\n",
        "\n",
        "Sample the paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8b8KAL-hswD"
      },
      "outputs": [],
      "source": [
        "# Code2Seq will use RNN/LSTM/... structures, so we don't need module. We need to define preprocess function.\r\n",
        "def code2seq_sample(tree, num):\r\n",
        "    results = []\r\n",
        "    terminals = list_terminal(tree)\r\n",
        "    if num == -1:\r\n",
        "        for i in range(len(terminals)):\r\n",
        "            for j in range(i + 1, len(terminals)):\r\n",
        "                left = terminals[i]\r\n",
        "                right = terminals[j]\r\n",
        "                results.append(terminal_to_path(tree, left, right))\r\n",
        "        # Sample all paths\r\n",
        "    else:\r\n",
        "        l = []\r\n",
        "        for i in range(len(terminals)):\r\n",
        "            for j in range(i + 1, len(terminals)):\r\n",
        "                l.append((i, j))\r\n",
        "        indices = random.choices(l, k=num)\r\n",
        "        for i in indices:\r\n",
        "            left = terminals[i]\r\n",
        "            right = terminals[j]\r\n",
        "            results.append(terminal_to_path(tree, left, right))\r\n",
        "        # Sample n paths\r\n",
        "    return results\r\n",
        "\r\n",
        "def terminal_to_path(tree, first, second):\r\n",
        "    root = tree\r\n",
        "    for i in range(len(first)):\r\n",
        "        if first[i] == second[i]:\r\n",
        "            if first[i]:\r\n",
        "                root = root[1]\r\n",
        "            else:\r\n",
        "                root = root[2]\r\n",
        "        else:\r\n",
        "            break\r\n",
        "    # i is current index of first/second\r\n",
        "    left_index = []\r\n",
        "    left_root = root\r\n",
        "\r\n",
        "    for j in range(i, len(first)):\r\n",
        "        if first[j]:\r\n",
        "            left_root = left_root[1]\r\n",
        "        else:\r\n",
        "            left_root = left_root[2]\r\n",
        "        left_index.append(left_root[0])\r\n",
        "    \r\n",
        "    right_index = []\r\n",
        "    right_root = root\r\n",
        "    \r\n",
        "    for j in range(i, len(second)):\r\n",
        "        if first[j]:\r\n",
        "            right_root = right_root[1]\r\n",
        "        else:\r\n",
        "            right_root = right_root[2]\r\n",
        "        right_index.append(right_root[0])\r\n",
        "\r\n",
        "    return list(left_index.reverse()) + [root[0]] + right_index\r\n",
        "\r\n",
        "# Returns list of terminals. The terminal's position is encoded as True(left), False(right). If unary, use True.\r\n",
        "def list_terminal(tree):\r\n",
        "    if len(tree) == 1:\r\n",
        "        return [[]]\r\n",
        "    elif len(tree) == 2:\r\n",
        "        l = list_terminal(tree[1])\r\n",
        "        return [t + [True] for t in l]\r\n",
        "    elif len(tree) == 3:\r\n",
        "        l = list_terminal(tree[1])\r\n",
        "        l2 = list_terminal(tree[2])\r\n",
        "        return [t + [True] for t in l] + [t + [False] for t in l2]\r\n",
        "    else:\r\n",
        "        raise ValueError(\"Tree is expected to be at most binary.\")\r\n",
        "\r\n",
        "class code2seq(nn.Module):\r\n",
        "    def __init__(self, in_dim, lstm_dim, lstm_depth, attention_dim, attention_head, attention_depth, lstm_bidirectional = False):\r\n",
        "        super(code2seq, self).__init__()\r\n",
        "        self.in_dim = in_dim\r\n",
        "        self.lstm_dim = lstm_dim\r\n",
        "        self.lstm_depth = lstm_depth\r\n",
        "        self.attention_dim = attention_dim\r\n",
        "        self.attention_head = attention_head\r\n",
        "        self.attention_depth = attention_depth\r\n",
        "        self.lstm_bidirectional = lstm_bidirectional\r\n",
        "\r\n",
        "        self.path_encoder = nn.LSTM(input_size = self.in_dim,\r\n",
        "                                    hidden_size = self.lstm_dim,\r\n",
        "                                    num_layers = self.lstm_depth,\r\n",
        "                                    bidirectional = lstm_bidirectional,\r\n",
        "                                    batch_first = True)\r\n",
        "        self.transformer = nn.Transformer()\r\n",
        "        self.decoder = nn.Linear(self.lstm_dim, self.in_dim)\r\n",
        "\r\n",
        "    def forward(self, paths):\r\n",
        "        # input : (batch_size, path_num, path_length, in_dim)\r\n",
        "        paths = paths.reshape(paths.shape[0] * paths.shape[1], -1, self.in_dim)\r\n",
        "        # reshape to (batch_size * path_num, path_length, in_dim)\r\n",
        "        \r\n",
        "        encoded = self.path_encoder(paths)[-1] # Get last output for encoding of path, having (batch_size * path_num, in_dim)\r\n",
        "        encoded.reshape(paths.shape[0], paths.shape[1], self.in_dim) # to (batch_size, path_num, in_dim)\r\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl6XdXMNkafA"
      },
      "source": [
        "### 6. TBCNN\n",
        "\n",
        "Due to our tree structure (at most binary, windows size 2), TBCNN's implementation is identical to recursive NN. So we do not implement TBCNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWKp60rjbHC4"
      },
      "source": [
        "## 5. Define hyperparameters and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-2fo_ktbGbn"
      },
      "outputs": [],
      "source": [
        "# Shared\n",
        "\n",
        "args = Namespace()\n",
        "args.epoch = 20\n",
        "args.lr = 0.001\n",
        "args.optim = \"adam\"\n",
        "args.in_dim = len(env.word2id)\n",
        "\n",
        "# Child Sum LSTM\n",
        "cslstm_args = Namespace()\n",
        "\n",
        "cslstm_args.nn_type = \"ReNN\"\n",
        "cslstm_args.cell_dim = 128\n",
        "cslstm_args.depth = 4\n",
        "\n",
        "# Binary Tree LSTM\n",
        "btlstm_args = Namespace()\n",
        "\n",
        "btlstm_args.nn_type = \"ReNN\"\n",
        "btlstm_args.cell_dim = 128\n",
        "btlstm_args.depth = 4\n",
        "btlstm_args.lr = 0.001\n",
        "\n",
        "# ReNN\n",
        "renn_args = Namespace()\n",
        "\n",
        "renn_args.nn_type = \"ReNN\"\n",
        "renn_args.cell_dim = 128\n",
        "renn_args.depth = 4\n",
        "\n",
        "# Comp Sem\n",
        "compsem_args = Namespace()\n",
        "\n",
        "compsem_args.nn_type = \"CompSem\"\n",
        "compsem_args.cell_dim = 100\n",
        "# compsem is not stackable\n",
        "\n",
        "# Code2Seq\n",
        "code2seq_args = Namespace()\n",
        "\n",
        "code2seq_args.nn_type = \"Code2Seq\"\n",
        "code2seq_args.cell_dim = 100 # \n",
        "code2seq_args.path_depth = 5 # How many layers we will use to encode each paths\n",
        "code2seq_args.path_type = \"LSTM\" # What layer to use when encoding path\n",
        "code2seq_args.model_type = \"attention\"\n",
        "code2seq_args.model_dim = 1024\n",
        "code2seq_args.model_head = 6\n",
        "code2seq_args.model_depth = 8\n",
        "\n",
        "# Should use attention?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2A-u7mGkr0X"
      },
      "source": [
        "## 6. Implement Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItwyrZhUa3O8"
      },
      "outputs": [],
      "source": [
        "layers = []\r\n",
        "for i in range(cslstm_args.depth):\r\n",
        "    if i == 0:\r\n",
        "        layers.append(ChildSumTreeLSTM(args.in_dim, cslstm_args.cell_dim, return_sequence = (i != cslstm_args.depth - 1)))\r\n",
        "    else:\r\n",
        "        layers.append(ChildSumTreeLSTM(cslstm_args.cell_dim, cslstm_args.cell_dim, return_sequence = (i != cslstm_args.depth - 1)))\r\n",
        "\r\n",
        "cslstm = nn.Sequential(*layers)\r\n",
        "cslstm_decoder = nn.Sequential()\r\n",
        "\r\n",
        "layers = []\r\n",
        "for i in range(btlstm_args.depth):\r\n",
        "    if i == 0:\r\n",
        "        layers.append(BinaryTreeLSTM(args.in_dim, btlstm_args.cell_dim, return_sequence = (i != cslstm_args.depth - 1)))\r\n",
        "    else:\r\n",
        "        layers.append(BinaryTreeLSTM(btlstm_args.cell_dim, btlstm_args.cell_dim, return_sequence = (i != cslstm_args.depth - 1)))\r\n",
        "\r\n",
        "btlstm = nn.Sequential(*layers)\r\n",
        "\r\n",
        "layers = []\r\n",
        "for i in range(renn_args.depth):\r\n",
        "    if i == 0:\r\n",
        "        layers.append(RecursiveNN(args.in_dim, renn_args.cell_dim, return_sequence = (i != cslstm_args.depth - 1)))\r\n",
        "    else:\r\n",
        "        layers.append(RecursiveNN(renn_args.cell_dim, renn_args.cell_dim, return_sequence = (i != cslstm_args.depth - 1)))\r\n",
        "\r\n",
        "renn = nn.Sequential(*layers)\r\n",
        "\r\n",
        "compsem = CompositionalSemantics(compsem_args.cell_dim)\r\n",
        "\r\n",
        "code_seq = code2seq(args.in_dim, code2seq_args.cell_dim, code2seq_args.path_depth, \r\n",
        "                    code2seq_args.model_dim, code2seq_args.model_head, code2seq_args.model_depth)\r\n",
        "\r\n",
        "lstm_enocder = nn.LSTM(args.in_dim, 128, 4, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\r\n",
        "\r\n",
        "def count_parameters(model):\r\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\r\n",
        "    total_params = 0\r\n",
        "    for name, parameter in model.named_parameters():\r\n",
        "        if not parameter.requires_grad: continue\r\n",
        "        param = parameter.numel()\r\n",
        "        table.add_row([name, param])\r\n",
        "        total_params+=param\r\n",
        "    print(table)\r\n",
        "    print(f\"Total Trainable Params: {total_params}\")\r\n",
        "    return total_params\r\n",
        "\r\n",
        "count_parameters(lstm_enocder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers):\r\n",
        "        super(Decoder, self).__init__()\r\n",
        "\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.emb_dim = emb_dim\r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_layers = n_layers\r\n",
        "\r\n",
        "        self.embedding = nn.Linear(self.output_dim, self.emb_dim)\r\n",
        "        self.layers = nn.LSTM(self.emb_dim, self.hid_dim, self.n_layers)\r\n",
        "        self.fc_out = nn.Linear(self.hid_dim, self.output_dim)\r\n",
        "\r\n",
        "    def forward(self, hidden, cell):\r\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\r\n",
        "f_tree = env.sympy_to_tree(f)\r\n",
        "bef = datetime.today()\r\n",
        "samples = code2seq_sample(f_tree, -1)\r\n",
        "samples = [[env.word2id[w] for t in sample] for sample in samples]\r\n",
        "print((datetime.today() - bef).seconds)\r\n",
        "output = code_seq(samples)\r\n",
        "print((datetime.today() - bef).seconds)\r\n",
        "output.sum().backward()\r\n",
        "print((datetime.today() - bef).seconds)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QI4frT0oGzi",
        "outputId": "a126a203-1875-4cd0-86b3-d9806c72685d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Testing the modules. I recommend not executing these.\r\n",
        "\r\n",
        "\r\n",
        "words = [env.word2id[w] if w else -1 for w in f_postfix]\r\n",
        "words = [[1 if i == j else 0 for i in range(len(env.word2id))] for j in words]\r\n",
        "words = torch.Tensor(words).unsqueeze(dim=0)\r\n",
        "words = words.repeat_interleave(16, dim=0)\r\n",
        "words2 = [env.word2id[w] if w else -1 for w in f_prefix]\r\n",
        "words2 = [[1 if i == j else 0 for i in range(len(env.word2id))] for j in words2]\r\n",
        "words2 = torch.Tensor(words2).unsqueeze(dim=0)\r\n",
        "words2 = words2.repeat_interleave(16, dim=0)\r\n",
        "from datetime import datetime\r\n",
        "begin = datetime.today()\r\n",
        "output = cslstm(words)\r\n",
        "print(output[0].shape)\r\n",
        "print(output[1].shape)\r\n",
        "print((datetime.today() - begin).seconds)\r\n",
        "output[1].sum().backward()\r\n",
        "print((datetime.today() - begin).seconds)\r\n",
        "output = btlstm(words)\r\n",
        "print(output[0].shape)\r\n",
        "print(output[1].shape)\r\n",
        "print((datetime.today() - begin).seconds)\r\n",
        "output[1].sum().backward()\r\n",
        "print((datetime.today() - begin).seconds)\r\n",
        "output = renn(words)\r\n",
        "print(output.shape)\r\n",
        "print((datetime.today() - begin).seconds)\r\n",
        "output.sum().backward()\r\n",
        "print((datetime.today() - begin).seconds)\r\n",
        "\r\n",
        "None # no output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm_encoder = nn.LSTM(args.in_dim, 128, 4, batch_first=True)\n",
        "begin = datetime.today()\n",
        "output = lstm_encoder(words2)\n",
        "print(output[0].shape)\n",
        "print((datetime.today() - begin).microseconds)\n",
        "output[0].sum().backward()\n",
        "print((datetime.today() - begin).microseconds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18QcMQVMS4_i"
      },
      "outputs": [],
      "source": [
        "def train(net, partition, preprocess, optimizer, criterion, model_args, args):\n",
        "    trainloader = torch.utils.data.DataLoader(partition['train'], \n",
        "                                              batch_size=args.batch_size, \n",
        "                                              shuffle=True, num_workers=2)\n",
        "    net.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    train_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.view(-1, args.in_dim)\n",
        "        inputs = preprocess(inputs)\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    train_acc = 100 * correct / total\n",
        "    return net, train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sKqI-bNdfo_"
      },
      "outputs": [],
      "source": [
        "def validate(net, partition, preprocess, criterion, args):\n",
        "    valloader = torch.utils.data.DataLoader(partition['val'], \n",
        "                                            batch_size=args.test_batch_size, \n",
        "                                            shuffle=False, num_workers=2)\n",
        "    net.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0 \n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            inputs, labels = data\n",
        "            inputs = images.view(-1, args.in_dim)\n",
        "            inputs = preprocess(inputs)\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(valloader)\n",
        "        val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0BeQFLrcfbm"
      },
      "outputs": [],
      "source": [
        "def test(net, partition, args):\n",
        "    testloader = torch.utils.data.DataLoader(partition['test'], \n",
        "                                             batch_size=args.test_batch_size, \n",
        "                                             shuffle=False, num_workers=2)\n",
        "    net.eval()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.view(-1, args.in_dim)\n",
        "            inputs = preprocess(inputs)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGEbsr0KfARX"
      },
      "outputs": [],
      "source": [
        "def experiment(partition, model_args, args):\n",
        "    if model_args.name == \"\":\n",
        "        net = TODO()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CS470_SymbolicIntegration.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}